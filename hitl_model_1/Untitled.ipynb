{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from numpy.core._multiarray_umath import ndarray\n",
    "from torch import LongTensor as LT\n",
    "import os\n",
    "import sys\n",
    "import tangent\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append('./..')\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# the columns are the older basis vectors for the qr function ; thus transpose\n",
    "# ========================================\n",
    "def gramSchmidt(V):\n",
    "    from scipy.linalg import qr\n",
    "    _basis, _ = qr(V.transpose(),mode='economic')\n",
    "    return _basis.transpose()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Reduce the avg cosine loss between W and (x1*x2)\n",
    "# Such that W. (x1x2) is maximized\n",
    "# -----------------------------------------------------\n",
    "def cosine_loss(X, Y):\n",
    "    xnorm = np.sqrt(np.sum(X*X))\n",
    "    ynorm = np.sqrt(np.sum(Y*Y))\n",
    "    similarity = np.sum(X*Y) / (xnorm * ynorm)\n",
    "    return 1 - similarity\n",
    "\n",
    "# =====================================================================\n",
    "# Combine Projected GD and Confidence weighted GD \n",
    "# =====================================================================\n",
    "class onlineGD:\n",
    "    def __init__(self, num_coeff, emb_dim):\n",
    "        self.num_coeff = num_coeff\n",
    "        self.coeff_mask: ndarray = np.zeros(num_coeff)\n",
    "        self.prior_grad_vectors = {\n",
    "            k: [] for k in range(num_coeff)\n",
    "        }\n",
    "        self.W_cur = None\n",
    "        self.emb_dim = emb_dim\n",
    "        self.gradient_fn = tangent.grad(cosine_loss, verbose = False)\n",
    "        self.W_orig = None\n",
    "        return\n",
    "\n",
    "    def set_original_W(self, W):\n",
    "        self.W_orig = W\n",
    "        self.W_cur = W\n",
    "        \n",
    "    # ------------------------------------\n",
    "    # list_feature_mod_idx: A list of list of indices for each sample.\n",
    "    # empty list for a sample means no explanation\n",
    "    # signs :\n",
    "    # ------------------------------------\n",
    "    def update_weight(\n",
    "            self,\n",
    "            label = [],\n",
    "            list_feature_mod_idx = [],\n",
    "            X = None\n",
    "    ):\n",
    "        update_mask = []\n",
    "        W = self.W_cur\n",
    "        \n",
    "        emb_dim = self.emb_dim\n",
    "        for _label,_feat_idx in zip(label, list_feature_mod_idx):\n",
    "\n",
    "            _mask = self.coeff_mask.copy()\n",
    "            # Update on the positive labels only\n",
    "            if _label == 1:\n",
    "                for _f in _feat_idx:\n",
    "                    _mask[_f] = 1\n",
    "            update_mask.append(_mask)\n",
    "        update_mask = np.array(update_mask)\n",
    "        \n",
    "        print(update_mask)\n",
    "        num_samples = update_mask.shape[0]\n",
    "\n",
    "        # Output mask shape : num_samples, num_coeff, coeff_dim\n",
    "        output_mask = np.broadcast_to(update_mask.reshape([ update_mask.shape[0],update_mask.shape[1],1]), [update_mask.shape[0], update_mask.shape[1], emb_dim])\n",
    "        # tiled_W shape: [ Num_samples, num_coeff, coeff_dim ]\n",
    "        tiled_W = np.tile(W.reshape([1,W.shape[0],W.shape[1]] ),(num_samples ,1,1))\n",
    "        \n",
    "        gradient_values = np.zeros(tiled_W.shape)\n",
    "        for i in range(num_samples):\n",
    "            for j in range(num_coeff):\n",
    "                g =  self.gradient_fn (tiled_W[i][j],x[i][j])\n",
    "                g = update_mask[i][j] * g\n",
    "                gradient_values[i][j]=g\n",
    "        divisor = np.sum(update_mask,axis=0)\n",
    "        divisor = np.reciprocal(divisor)\n",
    "        divisor =  np.where(divisor == np.inf, 0, divisor)\n",
    "        divisor = divisor.reshape([-1,1])\n",
    "        # --------------------------------\n",
    "        # Average gradients over the batch\n",
    "        \n",
    "        avg_gradients = np.multiply(np.sum(gradient_values,axis=0), divisor)\n",
    "        \n",
    "        \n",
    "        # =================================\n",
    "        # Calculate the projection of current gradient on each of the prior gradients for the same term \n",
    "        # =================================\n",
    "        coeff_update_flag = np.sum(update_mask,axis=0)\n",
    "        coeff_update_flag = np.where(coeff_update_flag > 0, True, False )\n",
    "        cur_gradient = avg_gradients \n",
    "        sum_grad_projections = [] \n",
    "\n",
    "        # ==================================\n",
    "        # Create orthonormal basis if and only more than 2 prior vectors available\n",
    "        # ==================================\n",
    "        for i in range(num_coeff):\n",
    "            _x = cur_gradient[i]\n",
    "            # IF no update needed, store 0\n",
    "            if not coeff_update_flag[i]:\n",
    "                g_proj_i = np.zeros(_x.shape)\n",
    "                sum_grad_projections.append(g_proj_i)\n",
    "                continue\n",
    "                \n",
    "            # Gram Scmidt process : get the bases\n",
    "            bases =  np.array( self.prior_grad_vectors[i])\n",
    "            \n",
    "            if bases.shape[0] >  1:\n",
    "                bases = gramSchmidt(bases)\n",
    "                g_proj_i = np.zeros(_x.shape)\n",
    "                # Add up sum of all projections\n",
    "                for orth_base in bases:\n",
    "                    _g_proj = np.dot(_x, orth_base) / np.linalg.norm(orth_base) * orth_base\n",
    "                    g_proj_i += _g_proj\n",
    "            else:\n",
    "                g_proj_i = _x\n",
    "            sum_grad_projections.append(g_proj_i)\n",
    "        # --------\n",
    "        # Add up the multiple projections\n",
    "        sum_grad_projections = np.array(sum_grad_projections)\n",
    "        final_gradient = sum_grad_projections   \n",
    "        \n",
    "        # Save avg_gradients\n",
    "        for i in range(num_coeff):\n",
    "            if coeff_update_flag[i]:\n",
    "                self.prior_grad_vectors[i].append(avg_gradients[i])\n",
    "                \n",
    "                \n",
    "        # Update the weights\n",
    "        W = W - final_gradient\n",
    "        self.W_cur = W\n",
    "        return final_gradient, W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_coeff = 6\n",
    "emb_dim = 4\n",
    "W = np.random.random([num_coeff,emb_dim])\n",
    "x = np.random.random([4,num_coeff,emb_dim])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "obj = onlineGD(num_coeff,emb_dim)\n",
    "obj.set_original_W(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.19448528, -0.01524198, -0.60491012, -0.35236459],\n",
       "        [ 0.29224515, -0.13482543, -0.3727943 , -0.36146961],\n",
       "        [-0.12759546, -0.10227231,  0.27686705, -0.36118204],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ]]),\n",
       " array([[0.81977526, 0.35695937, 0.01644474, 0.79943619],\n",
       "        [0.59786294, 0.86302818, 0.63315193, 0.70454064],\n",
       "        [0.63945738, 0.65238747, 0.38299497, 0.91117632],\n",
       "        [0.9648154 , 0.78576212, 0.65959916, 0.58973466],\n",
       "        [0.37025492, 0.12512023, 0.65381574, 0.27593393],\n",
       "        [0.6044633 , 0.53715762, 0.50104947, 0.40531476]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.update_weight(\n",
    "    [1,1,0,0],\n",
    "    [(1,2),(3,),(),()],\n",
    "    x\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.01803408,  0.02273411, -0.24438613,  0.17647168],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [-0.06388864,  0.04119739,  0.10523287, -0.0680681 ],\n",
       "        [ 0.23717967, -0.61888577,  0.05226264, -0.16145877],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ]]),\n",
       " array([[0.81977526, 0.35695937, 0.01644474, 0.79943619],\n",
       "        [0.57982887, 0.84029406, 0.87753807, 0.52806896],\n",
       "        [0.63945738, 0.65238747, 0.38299497, 0.91117632],\n",
       "        [1.02870404, 0.74456473, 0.55436629, 0.65780277],\n",
       "        [0.13307525, 0.74400599, 0.6015531 , 0.43739269],\n",
       "        [0.6044633 , 0.53715762, 0.50104947, 0.40531476]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.random([4,num_coeff,emb_dim])\n",
    "obj.update_weight(\n",
    "    [0,0,1,1],\n",
    "    [(),(),(1,3),(4,)],\n",
    "    x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [],\n",
       " 1: [array([ 0.19448528, -0.01524198, -0.60491012, -0.35236459]),\n",
       "  array([ 0.01803408,  0.02273411, -0.24438613,  0.17647168])],\n",
       " 2: [array([ 0.29224515, -0.13482543, -0.3727943 , -0.36146961])],\n",
       " 3: [array([-0.12759546, -0.10227231,  0.27686705, -0.36118204]),\n",
       "  array([-0.06388864,  0.04119739,  0.10523287, -0.0680681 ])],\n",
       " 4: [array([ 0.23717967, -0.61888577,  0.05226264, -0.16145877])],\n",
       " 5: []}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.prior_grad_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [-0.10445204,  0.14417577, -0.4597388 ,  0.16331834],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [-0.59917113,  0.16085843, -0.2051899 ,  0.19087615],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ]]),\n",
       " array([[0.81977526, 0.35695937, 0.01644474, 0.79943619],\n",
       "        [0.57982887, 0.84029406, 0.87753807, 0.52806896],\n",
       "        [0.74390941, 0.50821169, 0.84273377, 0.74785798],\n",
       "        [1.02870404, 0.74456473, 0.55436629, 0.65780277],\n",
       "        [0.73224637, 0.58314757, 0.806743  , 0.24651654],\n",
       "        [0.6044633 , 0.53715762, 0.50104947, 0.40531476]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.random([4,num_coeff,emb_dim])\n",
    "obj.update_weight(\n",
    "    [0,1,0,1],\n",
    "    [(),(2,),(),(4,)],\n",
    "    x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random([4,num_coeff,emb_dim])\n",
    "grad3 = obj.update_weight(\n",
    "    [0,1,0,1],\n",
    "    [(),(2,),(),(4,)],\n",
    "    x\n",
    ")\n",
    "\n",
    "\n",
    "# =================================\n",
    "# Calculate the projection of current gradient on each of the prior gradients for the same term \n",
    "# =================================\n",
    "coeff_update_flag = np.sum(update_mask,axis=0)\n",
    "coeff_update_flag = np.where(coeff_update_flag > 0, True, False )\n",
    "print(coeff_update_flag)\n",
    "cur_gradient = grad3 \n",
    "sum_grad_projections = [] \n",
    "\n",
    "# ==================================\n",
    "# Create orthonormal basis if and only more than 2 prior vectors available\n",
    "# ==================================\n",
    "for i in range(num_coeff):\n",
    "    _x = cur_gradient[i]\n",
    "    # IF no update needed, store 0\n",
    "    if not coeff_update_flag[i]:\n",
    "        g_proj_i = np.zeros(_x.shape)\n",
    "        sum_grad_projections.append(g_proj_i)\n",
    "        continue\n",
    "    # Gram Scmidt process : get the bases\n",
    "    bases =  np.array( prior_grad_vectors[i])\n",
    "    if bases.shape[0] >  1:\n",
    "        bases = gramSchmidt(bases)\n",
    "        g_proj_i = np.zeros(_x.shape)\n",
    "        # Add up sum of all projections\n",
    "        for orth_base in bases:\n",
    "            _g_proj = np.dot(_x, orth_base) / np.linalg.norm(orth_base) * orth_base\n",
    "            g_proj_i += _g_proj\n",
    "    else:\n",
    "        g_proj_i = _x\n",
    "    sum_grad_projections.append(g_proj_i)\n",
    "# Add up the multiple projections\n",
    "sum_grad_projections = np.array(sum_grad_projections)\n",
    "final_gradient = sum_grad_projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [-0.25,  0.07,  0.1 ,  0.14],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.43, -0.42, -0.38,  0.12],\n",
       "       [ 0.12, -0.04, -0.02, -0.18],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import qr\n",
    "qr(tmp[0].transpose(),mode='economic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [[-0.44, -0.16, -0.2 ,  0.15],\n",
    "       [ 0.16,  0.06, -0.21,  0.04],\n",
    "]\n",
    "tmp = np.array(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.44, -0.16, -0.2 ,  0.15])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[0].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected a 2-D array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-318-9f9677a7130c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'economic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/graph1/lib/python3.7/site-packages/scipy/linalg/decomp_qr.py\u001b[0m in \u001b[0;36mqr\u001b[0;34m(a, overwrite_a, lwork, mode, pivoting, check_finite)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expected a 2-D array\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0moverwrite_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverwrite_a\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_datacopied\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: expected a 2-D array"
     ]
    }
   ],
   "source": [
    "qr(tmp[0].transpose(),mode='economic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9973464794142505"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.001100000000000101"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40000000000000013\n",
      "[0.5  0.25] [-0.64  1.28]\n",
      "[ 1.14 -1.03]\n",
      "0.03652380413201883\n",
      "0.012477723095580373\n"
     ]
    }
   ],
   "source": [
    "y1 = np.array([0.50,-0.250])\n",
    "x0 = np.array([0.50, 0.250])\n",
    "print(cosine_loss(x0,y1))\n",
    "x1 = tangent_cosine_loss(x0,y1)\n",
    "print(x0, x1)\n",
    "x2 = x0 - x1\n",
    "print(x2)\n",
    "print(cosine_loss(x2,y1))\n",
    "x2 = x0 - x1\n",
    "x1 = tangent_cosine_loss(x2,y1)\n",
    "x2 = x2 -x1\n",
    "print(cosine_loss(x2,y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 1., 1., 0.])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.random([6,emb_dim])\n",
    "label =  [1,0,1,1]\n",
    "list_feature_mod_idx = [(1,2),(),(2,3),(4,)]\n",
    "coeff_mask = np.zeros(num_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> (1, 2)\n",
      ">> ()\n",
      ">> (2, 3)\n",
      ">> (4,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_mask = []\n",
    "for _label,_feat_idx in zip(label, list_feature_mod_idx):\n",
    "    _mask = coeff_mask.copy()\n",
    "    print('>>', _feat_idx)\n",
    "    # Update on the positive labels only\n",
    "    if _label == 1:\n",
    "        \n",
    "        for _f in _feat_idx:\n",
    "            _mask[_f] = 1\n",
    "    update_mask.append(_mask)\n",
    "update_mask = np.array(update_mask)\n",
    "update_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00e+00,  0.00e+00,  0.00e+00,  0.00e+00],\n",
       "       [ 3.86e-01, -2.90e-01, -3.79e-01, -1.50e-01],\n",
       "       [ 1.85e-01, -1.48e-02, -5.68e-01, -7.95e-02],\n",
       "       [ 9.63e-02, -7.29e-02,  1.03e-01, -6.63e-01],\n",
       "       [-4.64e-02, -1.07e-03,  1.34e-01,  2.17e-04],\n",
       "       [ 0.00e+00,  0.00e+00,  0.00e+00,  0.00e+00]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = update_mask.shape[0]\n",
    "\n",
    "# Output mask shape : num_samples, num_coeff, coeff_dim\n",
    "output_mask = np.broadcast_to(update_mask.reshape([ update_mask.shape[0],update_mask.shape[1],1]), [update_mask.shape[0], update_mask.shape[1], emb_dim])\n",
    "# tiled_W shape: [ Num_samples, num_coeff, coeff_dim ]\n",
    "tiled_W = np.tile(W.reshape([1,W.shape[0],W.shape[1]] ),(num_samples ,1,1))\n",
    "\n",
    "grad_res = np.zeros(tiled_W.shape)\n",
    "for i in range(num_samples):\n",
    "    for j in range(num_coeff):\n",
    "        g = tangent_cosine_loss(tiled_W[i][j],x[i][j])\n",
    "        g = update_mask[i][j] * g\n",
    "        grad_res[i][j]=g\n",
    "divisor = np.sum(update_mask,axis=0)\n",
    "divisor = np.reciprocal(divisor)\n",
    "divisor =  np.where(divisor == np.inf, 0, divisor)\n",
    "divisor = divisor.reshape([-1,1])\n",
    "avg_gradients = np.multiply(np.sum(grad_res,axis=0), divisor)\n",
    "avg_gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
