{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 40 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "try:\n",
    "    import AD_result_fetcher\n",
    "except:\n",
    "    from . import AD_result_fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Try to see if we reveal 10 , what is the change in precision in the next 100 ?\n",
    "# ==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = 'us_import1'\n",
    "PERCENTILE_THRESHOLD = 100\n",
    "PERCENTILE_THRESHOLD = 100 - 5\n",
    "REVEAL_STEP = 5\n",
    "UPDATE_scoreUB_percentile =  10 \n",
    "UPDATE_scoreUB = 0.5\n",
    "id_col = 'PanjivaRecordID'\n",
    "attribute_SHIPPER = 'ShipperPanjivaID'\n",
    "attribute_CONSIGNEE = 'ConsigneePanjivaID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22648 22648\n",
      "0.5650949312585849\n",
      "0.504619568345812\n",
      "Number of positive anomalies :  458\n"
     ]
    }
   ],
   "source": [
    "labelled_results = AD_result_fetcher.read_in_AD_result(DIR)\n",
    "\n",
    "score_threshold = np.percentile(labelled_results['score'],PERCENTILE_THRESHOLD)\n",
    "print(score_threshold)\n",
    "\n",
    "# The lowest score till which a new score should be calculated\n",
    "UPDATE_scoreUB = np.percentile(labelled_results['score'],100-UPDATE_scoreUB_percentile)\n",
    "print(UPDATE_scoreUB)\n",
    "\n",
    "print('Number of positive anomalies : ', len(labelled_results.loc[labelled_results['label']==1]))\n",
    "score_threshold = np.percentile(labelled_results['score'],PERCENTILE_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = labelled_results.copy()\n",
    "working_df['dynamic_score'] = labelled_results['score'].values\n",
    "# ------------------\n",
    "# Type conversion : to ensure no bugs\n",
    "# ------------------\n",
    "\n",
    "working_df['PanjivaRecordID'] = working_df['PanjivaRecordID'].astype(int)\n",
    "working_df['ConsigneePanjivaID'] = working_df['ConsigneePanjivaID'].astype(int)\n",
    "working_df['ShipperPanjivaID'] = working_df['ShipperPanjivaID'].astype(int)\n",
    "working_df = working_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_whiteList( target_df, ref_df ):\n",
    "    global attribute_SHIPPER\n",
    "    global attribute_CONSIGNEE\n",
    "    global id_col\n",
    "    global UPDATE_scoreUB\n",
    "    orig_target_df = target_df.copy()\n",
    "    fixed_df = target_df.loc[target_df['score']<UPDATE_scoreUB]\n",
    "    target_df = target_df.loc[target_df['score']>=UPDATE_scoreUB]\n",
    "    pos = ref_df.loc[ref_df['label']==1]\n",
    "   \n",
    "    target_entities = []\n",
    "    target_entities.extend(pos[attribute_SHIPPER].values.tolist())\n",
    "    target_entities.extend(pos[attribute_CONSIGNEE].values.tolist())\n",
    "    # ----------------------\n",
    "    # Do not update scores \n",
    "    # Simply order them by appending DFs\n",
    "    # ----------------------\n",
    "    df1 = target_df.loc[(target_df[attribute_CONSIGNEE].isin(target_entities)) & (target_df[attribute_CONSIGNEE].isin(target_entities))]\n",
    "    remainder = target_df.loc[~(target_df[id_col].isin(df1[id_col].values.tolist()))]\n",
    "    df2 = remainder.loc[(remainder[attribute_CONSIGNEE].isin(target_entities)) | (remainder[attribute_CONSIGNEE].isin(target_entities))]\n",
    "    remainder = remainder.loc[~(remainder[id_col].isin(df2[id_col]))]\n",
    "    res = df1.append(df2,ignore_index=True)\n",
    "    res = res.append(remainder,ignore_index=True)\n",
    "    res = res.append(fixed_df,ignore_index=True)\n",
    "        \n",
    "    for k in [50,100,150,200,250]:\n",
    "        # without input?\n",
    "        top_k_target = orig_target_df.head(k)\n",
    "        wo_input_precison = len(top_k_target.loc[top_k_target['label']==1])/k\n",
    "        \n",
    "        top_k = res.head(k)\n",
    "        prec = len(top_k.loc[top_k['label']==1])/k\n",
    "        print(' precision at next top {} : {:.3f}'.format(k, prec), ' || Without input {:.3f}'.format(wo_input_precison) )\n",
    "\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_whiteBlackList( target_df, ref_df ):\n",
    "    global attribute_SHIPPER\n",
    "    global attribute_CONSIGNEE\n",
    "    global id_col\n",
    "    global UPDATE_scoreUB\n",
    "    \n",
    "    orig_target_df = target_df.copy()\n",
    "    fixed_df = target_df.loc[target_df['score']<UPDATE_scoreUB]\n",
    "    target_df = target_df.loc[target_df['score']>=UPDATE_scoreUB]\n",
    "    pos = ref_df.loc[ref_df['label']==1]\n",
    "    neg = ref_df.loc[ref_df['label']!=1]\n",
    "    \n",
    "    target_entities = []\n",
    "    target_entities.extend(pos[attribute_SHIPPER].values.tolist())\n",
    "    target_entities.extend(pos[attribute_CONSIGNEE].values.tolist())\n",
    "    \n",
    "    neg_target_entities = []\n",
    "    neg_target_entities.extend(neg[attribute_SHIPPER].values.tolist())\n",
    "    neg_target_entities.extend(neg[attribute_CONSIGNEE].values.tolist())\n",
    "    # ----------------------\n",
    "    # Do not update scores \n",
    "    # Simply order them by appending DFs\n",
    "    # ----------------------\n",
    "    df1 = target_df.loc[(target_df[attribute_CONSIGNEE].isin(target_entities)) & (target_df[attribute_CONSIGNEE].isin(target_entities))]\n",
    "    remainder = target_df.loc[~(target_df[id_col].isin(df1[id_col].values.tolist()))]\n",
    "    df2 = remainder.loc[(remainder[attribute_CONSIGNEE].isin(target_entities)) | (remainder[attribute_CONSIGNEE].isin(target_entities))]\n",
    "    df2 = df2.loc[~(df2[attribute_CONSIGNEE].isin(neg_target_entities)) | ~(df2[attribute_CONSIGNEE].isin(neg_target_entities))]\n",
    "    remainder = remainder.loc[~(remainder[id_col].isin(df2[id_col]))]\n",
    "    df3 = remainder.loc[(remainder[attribute_CONSIGNEE].isin(neg_target_entities)) | (remainder[attribute_CONSIGNEE].isin(neg_target_entities))]\n",
    "    remainder = remainder.loc[~(remainder[id_col].isin(df3[id_col]))]\n",
    "    \n",
    "    \n",
    "    res = df1.append(df2,ignore_index=True)\n",
    "    res = res.append(remainder,ignore_index=True)\n",
    "    res = res.append(df3,ignore_index=True)\n",
    "    res = res.append(fixed_df,ignore_index=True)\n",
    "   \n",
    "    for k in [50,100,150,200,250]:\n",
    "        # without input?\n",
    "        top_k_target = orig_target_df.head(k)\n",
    "        wo_input_precison = len(top_k_target.loc[top_k_target['label']==1])/k\n",
    "        top_k = res.head(k)\n",
    "        prec = len(top_k.loc[top_k['label']==1])/k\n",
    "        print(' precision at next top {} : {:.3f}'.format(k, prec), ' || Without input {:.3f}'.format(wo_input_precison) )\n",
    "\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# label_top_k means how many positive anomalies get labelled by the annotator\n",
    "# -----------------------------\n",
    "def evaluate_on_input( df_cur, label_top_k = 25, scheme=1 ):\n",
    "    global id_col\n",
    "    df_cur = df_cur.sort_values(by='score',ascending=False)\n",
    "    seen_ids = []\n",
    "    count = 0\n",
    "    labelled_df = None\n",
    "    idx = 0\n",
    "    for i,row in df_cur.iterrows():\n",
    "        _id = int(row[id_col])\n",
    "        idx = i\n",
    "        seen_ids.append(_id)\n",
    "        \n",
    "        if row['label']==1: \n",
    "            count +=1\n",
    "            if count > label_top_k : \n",
    "                break\n",
    "        \n",
    "    seen_ids = set(seen_ids)\n",
    "    labelled_df = df_cur.iloc[:idx,:]\n",
    "    unlabelled_df = df_cur.iloc[idx:,:]\n",
    "    \n",
    "    print('# of records revealed to find {} instances at the top :: {}'.format(\n",
    "        label_top_k, \n",
    "        len(labelled_df))\n",
    "    )\n",
    "    # ----\n",
    "    \n",
    "    if scheme == 1 :\n",
    "        eval_whiteList(unlabelled_df, labelled_df)\n",
    "    elif scheme == 2 :\n",
    "        eval_whiteBlackList(unlabelled_df, labelled_df)   \n",
    "    return\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of records revealed to find 5 instances at the top :: 11\n",
      " precision at next top 50 : 0.520  || Without input 0.460\n",
      " precision at next top 100 : 0.460  || Without input 0.410\n",
      " precision at next top 150 : 0.513  || Without input 0.433\n",
      " precision at next top 200 : 0.475  || Without input 0.460\n",
      " precision at next top 250 : 0.476  || Without input 0.488\n",
      "# of records revealed to find 10 instances at the top :: 24\n",
      " precision at next top 50 : 0.540  || Without input 0.420\n",
      " precision at next top 100 : 0.540  || Without input 0.410\n",
      " precision at next top 150 : 0.567  || Without input 0.433\n",
      " precision at next top 200 : 0.540  || Without input 0.480\n",
      " precision at next top 250 : 0.520  || Without input 0.488\n",
      "# of records revealed to find 20 instances at the top :: 44\n",
      " precision at next top 50 : 0.600  || Without input 0.320\n",
      " precision at next top 100 : 0.600  || Without input 0.430\n",
      " precision at next top 150 : 0.627  || Without input 0.433\n",
      " precision at next top 200 : 0.665  || Without input 0.490\n",
      " precision at next top 250 : 0.592  || Without input 0.488\n",
      "# of records revealed to find 30 instances at the top :: 73\n",
      " precision at next top 50 : 0.680  || Without input 0.400\n",
      " precision at next top 100 : 0.650  || Without input 0.450\n",
      " precision at next top 150 : 0.660  || Without input 0.500\n",
      " precision at next top 200 : 0.690  || Without input 0.510\n",
      " precision at next top 250 : 0.644  || Without input 0.516\n",
      "# of records revealed to find 40 instances at the top :: 105\n",
      " precision at next top 50 : 0.780  || Without input 0.520\n",
      " precision at next top 100 : 0.760  || Without input 0.540\n",
      " precision at next top 150 : 0.720  || Without input 0.560\n",
      " precision at next top 200 : 0.735  || Without input 0.540\n",
      " precision at next top 250 : 0.744  || Without input 0.544\n",
      "# of records revealed to find 50 instances at the top :: 123\n",
      " precision at next top 50 : 0.800  || Without input 0.500\n",
      " precision at next top 100 : 0.770  || Without input 0.550\n",
      " precision at next top 150 : 0.727  || Without input 0.547\n",
      " precision at next top 200 : 0.740  || Without input 0.545\n",
      " precision at next top 250 : 0.752  || Without input 0.540\n"
     ]
    }
   ],
   "source": [
    "evaluate_on_input( working_df.copy(), label_top_k = 5, scheme=1 )\n",
    "evaluate_on_input( working_df.copy(), label_top_k = 10, scheme=1 )\n",
    "evaluate_on_input( working_df.copy(), label_top_k = 20, scheme=1 )\n",
    "evaluate_on_input( working_df.copy(), label_top_k = 30, scheme=1 )\n",
    "evaluate_on_input( working_df.copy(), label_top_k = 40, scheme=1 )\n",
    "evaluate_on_input( working_df.copy(), label_top_k = 50, scheme=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of records revealed to find 5 instances at the top :: 11\n",
      " precision at next top 50 : 0.520  || Without input 0.460\n",
      " precision at next top 100 : 0.460  || Without input 0.410\n",
      " precision at next top 150 : 0.527  || Without input 0.433\n",
      " precision at next top 200 : 0.475  || Without input 0.460\n",
      " precision at next top 250 : 0.484  || Without input 0.488\n",
      "# of records revealed to find 10 instances at the top :: 24\n",
      " precision at next top 50 : 0.540  || Without input 0.420\n",
      " precision at next top 100 : 0.540  || Without input 0.410\n",
      " precision at next top 150 : 0.567  || Without input 0.433\n",
      " precision at next top 200 : 0.540  || Without input 0.480\n",
      " precision at next top 250 : 0.524  || Without input 0.488\n",
      "# of records revealed to find 20 instances at the top :: 44\n",
      " precision at next top 50 : 0.600  || Without input 0.320\n",
      " precision at next top 100 : 0.600  || Without input 0.430\n",
      " precision at next top 150 : 0.627  || Without input 0.433\n",
      " precision at next top 200 : 0.665  || Without input 0.490\n",
      " precision at next top 250 : 0.616  || Without input 0.488\n",
      "# of records revealed to find 30 instances at the top :: 73\n",
      " precision at next top 50 : 0.680  || Without input 0.400\n",
      " precision at next top 100 : 0.650  || Without input 0.450\n",
      " precision at next top 150 : 0.660  || Without input 0.500\n",
      " precision at next top 200 : 0.690  || Without input 0.510\n",
      " precision at next top 250 : 0.664  || Without input 0.516\n",
      "# of records revealed to find 40 instances at the top :: 105\n",
      " precision at next top 50 : 0.780  || Without input 0.520\n",
      " precision at next top 100 : 0.760  || Without input 0.540\n",
      " precision at next top 150 : 0.720  || Without input 0.560\n",
      " precision at next top 200 : 0.735  || Without input 0.540\n",
      " precision at next top 250 : 0.744  || Without input 0.544\n",
      "# of records revealed to find 50 instances at the top :: 123\n",
      " precision at next top 50 : 0.800  || Without input 0.500\n",
      " precision at next top 100 : 0.770  || Without input 0.550\n",
      " precision at next top 150 : 0.727  || Without input 0.547\n",
      " precision at next top 200 : 0.740  || Without input 0.545\n",
      " precision at next top 250 : 0.752  || Without input 0.540\n"
     ]
    }
   ],
   "source": [
    "evaluate_on_input( working_df.copy(), label_top_k = 5, scheme=2 )\n",
    "evaluate_on_input( working_df.copy(), label_top_k = 10, scheme=2 )\n",
    "evaluate_on_input( working_df.copy(), label_top_k = 20, scheme=2 )\n",
    "evaluate_on_input( working_df.copy(), label_top_k = 30, scheme=2 )\n",
    "evaluate_on_input( working_df.copy(), label_top_k = 40, scheme=2 )\n",
    "evaluate_on_input( working_df.copy(), label_top_k = 50, scheme=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
