{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n",
      "[nltk_data]     Temporary failure in name resolution>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import networkx as nx\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DBLP_Triplets.pickle','rb') as fh :\n",
    "    data_obj = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37791"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_obj[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('P162545', 'T35', 'PT')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_obj[2][80000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_label = pd.read_csv('author_label.txt',low_memory=False,header=None,sep='\\t',names=['ID','label','name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>366357</td>\n",
       "      <td>1</td>\n",
       "      <td>Hoi-Yee Hwang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421581</td>\n",
       "      <td>3</td>\n",
       "      <td>Tee Kiah Chia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30266</td>\n",
       "      <td>0</td>\n",
       "      <td>Soumyadeb Mitra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136630</td>\n",
       "      <td>3</td>\n",
       "      <td>Azin Ashkan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114115</td>\n",
       "      <td>0</td>\n",
       "      <td>A. Kumaran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4052</th>\n",
       "      <td>19076</td>\n",
       "      <td>2</td>\n",
       "      <td>Bon K. Sy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4053</th>\n",
       "      <td>84215</td>\n",
       "      <td>1</td>\n",
       "      <td>Sergei O. Kuznetsov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4054</th>\n",
       "      <td>52975</td>\n",
       "      <td>3</td>\n",
       "      <td>David R. H. Miller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4055</th>\n",
       "      <td>19543</td>\n",
       "      <td>3</td>\n",
       "      <td>Richard M. Tong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4056</th>\n",
       "      <td>15940</td>\n",
       "      <td>2</td>\n",
       "      <td>Brian Scassellati</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4057 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  label                 name\n",
       "0     366357      1        Hoi-Yee Hwang\n",
       "1     421581      3        Tee Kiah Chia\n",
       "2      30266      0      Soumyadeb Mitra\n",
       "3     136630      3          Azin Ashkan\n",
       "4     114115      0           A. Kumaran\n",
       "...      ...    ...                  ...\n",
       "4052   19076      2            Bon K. Sy\n",
       "4053   84215      1  Sergei O. Kuznetsov\n",
       "4054   52975      3   David R. H. Miller\n",
       "4055   19543      3      Richard M. Tong\n",
       "4056   15940      2    Brian Scassellati\n",
       "\n",
       "[4057 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 745, 3: 1006, 0: 1197, 2: 1109})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(author_label['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_file = 'author.txt' \n",
    "author_df = pd.read_csv(\n",
    "    author_file,\n",
    "    low_memory=False,\n",
    "    header=None,\n",
    "    sep='\\t',\n",
    "    names=['ID','name']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_file = 'paper.txt' \n",
    "paper_df = pd.read_csv(\n",
    "    paper_file,\n",
    "    low_memory=False,\n",
    "    header=None,\n",
    "    sep='\\t',\n",
    "    names=['ID','name']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_file = 'term.txt' \n",
    "term_df = pd.read_csv(\n",
    "    term_file,\n",
    "    low_memory=False,\n",
    "    header=None,\n",
    "    sep='\\t',\n",
    "    names=['ID','name']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_file = 'conf.txt' \n",
    "conf_df = pd.read_csv(\n",
    "    conf_file,\n",
    "    low_memory=False,\n",
    "    header=None,\n",
    "    sep='\\t',\n",
    "    names=['ID','name']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_ID_list = paper_df['ID'].values\n",
    "author_ID_list = author_df['ID'].values\n",
    "conf_ID_list = conf_df['ID'].values\n",
    "term_ID_list = term_df['ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "# Make sure all type of nodes have IDs starting from 0\n",
    "# --------------\n",
    "class node:\n",
    "    def __init__(_id,category):\n",
    "        self.id = _id\n",
    "        self.category = category\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in edges\n",
    "\n",
    "PA = pd.read_csv('paper_author.txt', sep='\\t', names = ['P','A'])\n",
    "PC = pd.read_csv('paper_conf.txt', sep='\\t', names = ['P','C'])\n",
    "PT = pd.read_csv('paper_term.txt', sep='\\t', names = ['P','T'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_dict = {\n",
    "    'P': {},\n",
    "    'A': {},\n",
    "    'C': {},\n",
    "    'T': {}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(df, val):\n",
    "    return df.loc[df['ID']==val].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df = pd.read_csv(\n",
    "    term_file,\n",
    "    low_memory=False,\n",
    "    header=None,\n",
    "    sep='\\t',\n",
    "    names=['ID','name']\n",
    ")\n",
    "\n",
    "rmv_terms = t_df.loc[t_df['name'].isin(set(stopwords.words('english')))]['ID'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Create graph \n",
    "# --------------------------\n",
    "G = nx.Graph()\n",
    "for i,row in PA.iterrows():\n",
    "    p = row['P']\n",
    "    a = row['A']\n",
    "    if a in list(author_label['ID']):\n",
    "        G.add_edge(p,a)\n",
    "    \n",
    "for i,row in PC.iterrows():\n",
    "    p = row['P']\n",
    "    c = row['C']\n",
    "    G.add_edge(p,c)  \n",
    "    \n",
    "for i,row in PT.iterrows():\n",
    "    p = row['P']\n",
    "    t = row['T']\n",
    "    if t not in rmv_terms:\n",
    "        G.add_edge(p,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 1197, 2: 1109, 3: 1006, 1: 745})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(author_label['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_0_ids =author_label.loc[author_label['label']==0]['ID'].values.tolist()\n",
    "label_1_ids =author_label.loc[author_label['label']==1]['ID'].values.tolist()\n",
    "label_2_ids =author_label.loc[author_label['label']==2]['ID'].values.tolist()\n",
    "label_3_ids =author_label.loc[author_label['label']==3]['ID'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26126 122694\n",
      "26126\n",
      " Rare Terms to remove  4670\n",
      "21456 116983\n"
     ]
    }
   ],
   "source": [
    "G1 = G.copy()\n",
    "print(G1.number_of_nodes(),G1.number_of_edges())\n",
    "\n",
    "for conn_comp in nx.connected_components(G1):\n",
    "    print(len(conn_comp))\n",
    "G1.number_of_edges()\n",
    "filter_terms = []\n",
    "for node in G1.nodes():\n",
    "    if node in list(term_df['ID']):\n",
    "        if nx.degree(G1,node) < 3 : \n",
    "            filter_terms.append(node)\n",
    "print(' Rare Terms to remove ',len(filter_terms))\n",
    "\n",
    "for n in filter_terms:\n",
    "    G1.remove_node(n)\n",
    "isolates = [n for n in nx.isolates(G1) ]\n",
    "for n in isolates:\n",
    "    G1.remove_node(n)\n",
    "\n",
    "print(G1.number_of_nodes(), G1.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================\n",
    "# Create synthetic ids for continuous ids in the riginal dataset\n",
    "# ==================================\n",
    "def get_df(id_list, valid_ids, label_df=None):\n",
    "    id_list = [i for i in id_list if i in valid_ids]\n",
    "    print(' >> ', len(id_list))\n",
    "    data = [( i,j) for i,j in enumerate(id_list)]\n",
    "    df = pd.DataFrame(np.array(data),columns=['synID','ID'])\n",
    "    print(df.head(10))\n",
    "    if label_df is not None:\n",
    "         df = df.merge(label_df, on=['ID'],how='inner')\n",
    "    return df\n",
    "\n",
    "valid_ids = list(G1.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >>  20\n",
      "   synID    ID\n",
      "0      0    36\n",
      "1      1   597\n",
      "2      2   755\n",
      "3      3  1194\n",
      "4      4  1201\n",
      "5      5  1234\n",
      "6      6  1798\n",
      "7      7  1801\n",
      "8      8  1902\n",
      "9      9  2180\n",
      " >>  4144\n",
      "   synID  ID\n",
      "0      0   2\n",
      "1      1   3\n",
      "2      2   5\n",
      "3      3   6\n",
      "4      4   8\n",
      "5      5   9\n",
      "6      6  11\n",
      "7      7  12\n",
      "8      8  13\n",
      "9      9  14\n",
      " >>  14376\n",
      "   synID    ID\n",
      "0      0  7601\n",
      "1      1  7604\n",
      "2      2  7605\n",
      "3      3  7610\n",
      "4      4  7612\n",
      "5      5  7613\n",
      "6      6  7621\n",
      "7      7  7630\n",
      "8      8  7631\n",
      "9      9  7632\n"
     ]
    }
   ],
   "source": [
    "C_df = get_df(conf_ID_list,valid_ids)\n",
    "T_df = get_df(term_ID_list,valid_ids)\n",
    "P_df = get_df(paper_ID_list,valid_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >>  4321\n",
      "   synID   ID\n",
      "0      0   76\n",
      "1      1  124\n",
      "2      2  192\n",
      "3      3  226\n",
      "4      4  234\n",
      "5      5  250\n",
      "6      6  310\n",
      "7      7  325\n",
      "8      8  337\n",
      "9      9  377\n"
     ]
    }
   ],
   "source": [
    "author_label_df = author_label[['ID','label']]\n",
    "A_df = get_df(author_ID_list,valid_ids,author_label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_df['type'] = 'C'\n",
    "P_df['type'] = 'P'\n",
    "T_df['type'] = 'T'\n",
    "\n",
    "C_df['label'] = None\n",
    "P_df['label'] = None\n",
    "T_df['label'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_df['type'] = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4050"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(A_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the edge lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116983"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G1.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes_df = A_df.copy()\n",
    "all_nodes_df = all_nodes_df.append(C_df,ignore_index=True)\n",
    "all_nodes_df = all_nodes_df.append(P_df,ignore_index=True)\n",
    "all_nodes_df = all_nodes_df.append(T_df,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          192\n",
       "1          226\n",
       "2          234\n",
       "3          435\n",
       "4          444\n",
       "         ...  \n",
       "22585    13401\n",
       "22586    13440\n",
       "22587    13451\n",
       "22588    13485\n",
       "22589    13548\n",
       "Name: ID, Length: 22590, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nodes_df['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edges_df = pd.DataFrame(columns=['n1','n2','edge_type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def setup_edges (e):\n",
    "    row1 = all_nodes_df.loc[all_nodes_df['ID']==e[0]]\n",
    "    row2 = all_nodes_df.loc[all_nodes_df['ID']==e[1]]\n",
    "    \n",
    "    id1 = row1['synID'].values.tolist()[0]\n",
    "    id2 = row2['synID'].values.tolist()[0]\n",
    "    type1 = row1['type'].values.tolist()[0]\n",
    "    type2 = row2['type'].values.tolist()[0]\n",
    "    \n",
    "    # Lexicographic ordering\n",
    "    if type1 > type2:\n",
    "        type1, type2 = type2, type1\n",
    "        row1, row2 = row2,row1\n",
    "        id1, id2 = id2, id1\n",
    "\n",
    "    \n",
    "    edge_type = type1 + '_' + type2\n",
    "    _dict = {\n",
    "            'n1':id1,\n",
    "            'n2':id2,\n",
    "            'edge_type' : edge_type\n",
    "        }\n",
    "    return _dict\n",
    "     \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=16)(delayed(setup_edges)(e) for  e in G1.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in results:\n",
    "#     edges_df = edges_df.append(r,ignore_index=True)\n",
    "\n",
    "edges_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df.to_csv('dblp_edges.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes_df.to_csv('dblp_nodes.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
